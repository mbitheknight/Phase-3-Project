{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "197bb954-645f-4376-8582-c97e817ca471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, auc, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f0ecb8f-e0ca-40c1-9214-af784ffa50e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57510, 16)\n",
      "(10642, 16)\n",
      "(57510, 1)\n",
      "(10642, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_scaled = pd.read_csv('Preprocessed Data/X_train_scaled.csv')\n",
    "x_test_scaled = pd.read_csv('Preprocessed Data/X_test_scaled.csv')\n",
    "y_train = pd.read_csv('Preprocessed Data/y_train.csv')\n",
    "y_test = pd.read_csv('Preprocessed Data/y_test.csv')\n",
    "\n",
    "print(x_train_scaled.shape)\n",
    "print(x_test_scaled.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28d2d17-feca-495f-b996-c50d789c0823",
   "metadata": {},
   "source": [
    "# Load the Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bae344f-d944-4cd8-85be-7c674eaeeab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (57510, 16)\n",
      "X_test_scaled shape: (10642, 16)\n",
      "y_train shape: (57510, 1)\n",
      "y_test shape: (10642, 1)\n"
     ]
    }
   ],
   "source": [
    "# To avail the classes notebook\n",
    "%run Phase_3_Project_Classes.ipynb \n",
    "\n",
    "# Path to the folder where the data is saved\n",
    "output_path = \"Preprocessed Data/\"\n",
    "\n",
    "# Load the datasets needed for modeling\n",
    "X_train_scaled = pd.read_csv(output_path + 'X_train_scaled.csv')\n",
    "X_test_scaled = pd.read_csv(output_path + 'X_test_scaled.csv')\n",
    "y_train = pd.read_csv(output_path + 'y_train.csv')\n",
    "y_test = pd.read_csv(output_path + 'y_test.csv')\n",
    "\n",
    "# Verify that the data has been loaded correctly\n",
    "print(f\"X_train_scaled shape: {X_train_scaled.shape}\")\n",
    "print(f\"X_test_scaled shape: {X_test_scaled.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2801f47b-4a06-4158-a202-1acd2808d6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status_Group\n",
      "0.0             28755\n",
      "1.0             28755\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution in training set\n",
    "print(y_train.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b476e81-6b51-4a0e-85c0-e3a422f87ef1",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00338d5d-ae92-4b6a-94f9-d749786526c8",
   "metadata": {},
   "source": [
    "## Model 1: Logistic Regression: Baseline Model\n",
    "The Logistic Regression model is implemented as a baseline to establish a point of comparison for evaluating other models. It uses the default configuration with standard hyperparameters. It serves as a starting point without applying advanced tuning or feature engineering, providing a benchmark for model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78a22552-34f3-4275-992f-de842e9bd4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "trainer = ModelTrainer(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "\n",
    "# Train the models\n",
    "logistic_model = trainer.logistic_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53d924d-cde6-474b-9031-bf418dee31fb",
   "metadata": {},
   "source": [
    "## Model 2. Cross-validated Untuned Decision Tree Classifier\n",
    "The untuned Decision Tree Classifier is trained using the training dataset without any hyperparameter optimization.\n",
    "The model is cross-validated during training to evaluate its performance on multiple subsets of the data. This serves as a foundation for later the comparison with a tuned decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc13c6ad-81ff-4316-9674-0d4df29ff0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models\n",
    "untuned_dt_model = trainer.untuned_decision_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8237fa9-db86-44ec-bcc5-da3fa5c83828",
   "metadata": {},
   "source": [
    "## Model 3 : Tuned and Cross Validated Decsion Tree Classifier\n",
    "This model leverages hyperparameter tuning and cross-validation to optimize the Decision Tree Classifier's performance. It uses GridSearchCV to systematically explore combinations of hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884846f3-4b11-4d6b-8953-d50835c88027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2304 candidates, totalling 11520 fits\n"
     ]
    }
   ],
   "source": [
    "# Train the models\n",
    "tuned_dt_model = trainer.tuned_decision_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d801f2a-0519-4f4b-935b-66dcfaab276c",
   "metadata": {},
   "source": [
    "# Model Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf354b07-d0d3-4e40-b151-455e1613bc32",
   "metadata": {},
   "source": [
    "## Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2e575-7168-4bee-944d-99be15cbdf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the evaluator\n",
    "evaluator = ModelEvaluator(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "# Train the models\n",
    "logistic_model = trainer.logistic_regression()\n",
    "\n",
    "\n",
    "# Evaluate the models\n",
    "logistic_results = evaluator.evaluate(logistic_model)\n",
    "\n",
    "# Print evaluation results\n",
    "print(\"Logistic Regression Evaluation:\")\n",
    "print(logistic_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44d6040-8324-44ae-975e-62f71fafe2f1",
   "metadata": {},
   "source": [
    "## Model 2. Cross-validated Untuned Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3771fb67-f996-4327-b2b4-6d3e2dcd2472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models\n",
    "untuned_dt_model = trainer.untuned_decision_tree()\n",
    "\n",
    "# Evaluate the models\n",
    "untuned_dt_results = evaluator.evaluate(untuned_dt_model)\n",
    "\n",
    "# Print evaluation results\n",
    "print(\"\\nUntuned Decision Tree Evaluation:\")\n",
    "print(untuned_dt_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36201212-8892-497c-9a47-ddd9e82ccf41",
   "metadata": {},
   "source": [
    "## Model 3 : Tuned and Cross Validated Decsion Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc3445-22e4-43de-859b-9dd3f6eed2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models\n",
    "tuned_dt_model = trainer.tuned_decision_tree()\n",
    "\n",
    "# Evaluate the models\n",
    "tuned_dt_results = evaluator.evaluate(tuned_dt_model)\n",
    "\n",
    "\n",
    "print(\"\\nTuned Decision Tree Evaluation:\")\n",
    "print(tuned_dt_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5f906d-22b1-439c-864c-cb3cf5737f2b",
   "metadata": {},
   "source": [
    "## Choosing the best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba81672a-512d-4870-8ec9-e74c0dcec6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC Curve for Logistic Regression (Model 1)\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, Baseline_Model.predict_proba(X_test_scaled)[:, 1])\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "# ROC-AUC Curve for Decision Tree (Untuned Model 2)\n",
    "fpr_dt, tpr_dt, _ = roc_curve(y_test, decision_tree.predict_proba(X_test_scaled)[:, 1])\n",
    "roc_auc_dt = auc(fpr_dt, tpr_dt)\n",
    "\n",
    "# ROC-AUC Curve for Tuned Decision Tree (Model 3)\n",
    "fpr_tuned, tpr_tuned, _ = roc_curve(y_test, best_dt_model.predict_proba(X_test_scaled)[:, 1])\n",
    "roc_auc_tuned = auc(fpr_tuned, tpr_tuned)\n",
    "\n",
    "# Plot all ROC curves on the same graph\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {roc_auc_lr:.2f})', color='blue')\n",
    "plt.plot(fpr_dt, tpr_dt, label=f'Untuned Decision Tree (AUC = {roc_auc_dt:.2f})', color='red')\n",
    "plt.plot(fpr_tuned, tpr_tuned, label=f'Tuned Decision Tree (AUC = {roc_auc_tuned:.2f})', color='green')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label='Random Classifier')\n",
    "\n",
    "# Add plot details\n",
    "plt.title('Comparison of ROC Curves for All Models')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e322ca-0f7d-4705-a329-a908b69b1f4b",
   "metadata": {},
   "source": [
    "Model 3 (Tuned Decision Tree) is the best model because of its smooth curve and its proximity to the top-left corner, indicating it has the highest overall classification performance.\n",
    "\n",
    "Model 2 (Untuned Decision Tree) is better than Model 1 (Logistic Regression), but still underperforms compared to the tuned decision tree due to sharp turns in the curve and overfitting signs.\n",
    "\n",
    "Model 1 (Logistic Regression) is the least effective of the three, but still provides a stable performance, though it's not as well-suited for this problem as the tuned decision tree.\n",
    "\n",
    "The Tuned Decision Tree (Model 3) should be chosen as the best model based on its ROC curve performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc58cded-8c0b-45ad-8d9b-aca0045c0f36",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "#### 1. Model Performance:\n",
    "Model 1 (Logistic Regression): Achieved moderate accuracy but struggled with false positives and false negatives. The absence of test_labels for validation hindered model performance assessment.\n",
    "\n",
    "Model 2 (Untuned Decision Tree): Overfitted on the training data and performed poorly on the test set. test_labels were missing, affecting performance evaluation.\n",
    "\n",
    "Model 3 (Tuned Decision Tree): Showed improvement in generalization, but again, the lack of test_labels prevented a proper performance evaluation.\n",
    "\n",
    "##### 2. Class Imbalance:\n",
    "Class imbalance was effectively managed through a combination of the SMOTE and Class Weights, but the missing test_labels compromised the ability to assess model performance effectively.\n",
    "\n",
    "#### 3. Test Labels Issue:\n",
    "The lack of test_labels for the test set prevented reliable evaluation of the models. This needs to be addressed to ensure accurate model assessment moving forward.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27221ba7-a148-4598-8164-af1fc0575881",
   "metadata": {},
   "source": [
    "\n",
    "## Recommendations\n",
    "\n",
    "#### 1.Feature Engineering:\n",
    "Continue with feature engineering, but ensure test_labels are available for evaluating how the new features impact model performance.\n",
    "\n",
    "#### 2. Additional Data Collection:\n",
    "Make sure test_labels are included in future data sets, as they are essential for accurate model evaluation and performance tracking.\n",
    "\n",
    "#### 3. Model Enhancements:\n",
    "Advanced models like Random Forests or Gradient Boosting Machines should be tested, but ensure proper validation using test_labels.\n",
    "\n",
    "#### 4. Evaluation Improvements:\n",
    "Ensure that test_labels are available for all test sets to compute key performance metrics and make informed decisions about model improvements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25be031-9a66-4d2f-abb7-56268fd4cadb",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Deployment: Prepare to deploy the tuned decision tree model once test_labels are included in the testing phase for accurate performance evaluation.\n",
    "- Iterative Data Collection and Testing: Update datasets with test_labels to ensure proper validation and further model tuning.\n",
    "- Future Exploration: Explore ensemble methods and ensure test_labels are always available for robust evaluation of model performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
